import OpenAI from "openai";
import ffmpeg from "fluent-ffmpeg";
import ffmpegStatic from "ffmpeg-static";
import fetch from "node-fetch"; // Para baixar o √°udio
import { Readable } from "stream";
import fs from "fs";
import path from "path";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, // Certifique-se de definir sua API Key no .env
});

export const getOpenAiCompletion = async (input: string): Promise<string> => {
  try {
    const temperature = 0.0; // Reduzido para zero para respostas determin√≠sticas
    const maxTokens = 500; // Limitar o tamanho da resposta
    const model = process.env.OPENAI_FINE_TUNED_MODEL || "gpt-3.5-turbo"; // Usa modelo treinado, se definido

    const completion = await openai.chat.completions.create({
      messages: [
        {
          role: "system",
          content: `
Voc√™ √© um assistente especializado em nutri√ß√£o materno-infantil da Dra. Sabrina.

INSTRU√á√ïES IMPORTANTES:
1. **Responda apenas com base nos exemplos de treinamento fornecidos e nas instru√ß√µes deste prompt.** N√£o invente ou assuma informa√ß√µes n√£o fornecidas.
2. Se o usu√°rio fizer uma pergunta que n√£o tenha resposta no treinamento ou instru√ß√µes fornecidas, responda com: 
   "Desculpe, n√£o possuo essa informa√ß√£o no momento. Entre em contato com a Dra. Sabrina para mais detalhes."
3. Caso o usu√°rio pergunte sobre qualquer conv√™nio, responda que A Dra. Sabrina atende os conv√™nios Amil e SulAm√©rica e explique sobre a modalidade de reembolso e nota fiscal, conforme o treinamento.
4. Mantenha a resposta simples, objetiva e no estilo amig√°vel, com emojis usados nos exemplos de treinamento.
5. Nunca tente adivinhar ou gerar informa√ß√µes al√©m do que foi fornecido.
6. Caso o usu√°rio pergunte sobre o endere√ßo responda que O Consult√≥rio de Nutri√ß√£o Materno Infantil\nQuadra 205, Lt 01, 7¬∞ And. SALA 708 Ed. Quartier Center. √Åguas Claras Sul\nlocaliza√ß√£o: https://maps.google.com/?q=-15.8424,-48.0222\nComo o consult√≥rio n√£o conta com recepcionista, a Dra pede que voc√™ entre e fique a vontade na recep√ß√£o, no hor√°rio da sua consulta ela te chama, ok? üòâüíö".
7. Caso a d√∫vida envolva valores ou conv√™nios, responda de forma clara e consistente com o treinamento: 
   - "A Dra. Sabrina atende os conv√™nios Amil e SulAm√©rica."
   - "O valor da consulta avulsa √© R$350 reais." 
   - Para outros conv√™nios, explique sobre reembolso e nota fiscal.
          `,
        }, // Contexto do sistema
        {
          role: "user",
          content: input, // Entrada do usu√°rio
        },
      ],
      model: model,
      temperature: temperature, // Determin√≠stico
      max_tokens: maxTokens, // Limitar resposta
    });

    return completion.choices[0].message?.content as string;
  } catch (error) {
    console.error("Erro ao chamar o modelo da OpenAI:", error);
    throw new Error("N√£o foi poss√≠vel receber o texto");
  }
};

const TWILIO_ACCOUNT_SID = process.env.TWILIO_ACCOUNT_SID || "";
const TWILIO_AUTH_TOKEN = process.env.TWILIO_AUTH_TOKEN || "";

export const transcribeAudio = async (audioUrl: string): Promise<string> => {
  try {
    console.log("Baixando o √°udio...");

    // Cria a URL autenticada usando Account SID e Auth Token
    const url = new URL(audioUrl);
    const authHeader = `Basic ${Buffer.from(
      `${TWILIO_ACCOUNT_SID}:${TWILIO_AUTH_TOKEN}`
    ).toString("base64")}`;

    // Baixa o √°udio com autentica√ß√£o
    const audioResponse = await fetch(url, {
      headers: { Authorization: authHeader },
    });

    if (!audioResponse.ok) {
      throw new Error(`Erro ao baixar o √°udio: ${audioResponse.statusText}`);
    }

    const audioBuffer = await audioResponse.buffer();

    // Caminhos tempor√°rios
    const tempDir = path.resolve("temp");
    const inputPath = path.join(tempDir, "input.ogg");
    const outputPath = path.join(tempDir, "output.mp3");

    // Cria o diret√≥rio 'temp' se n√£o existir
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    // Salva o √°udio localmente
    fs.writeFileSync(inputPath, audioBuffer);
    console.log("√Åudio salvo com sucesso.");

    // Converte o √°udio para MP3
    console.log("Convertendo o √°udio para MP3...");
    await new Promise<void>((resolve, reject) => {
      ffmpeg()
        .setFfmpegPath(ffmpegStatic as string)
        .input(inputPath)
        .audioCodec("libmp3lame")
        .toFormat("mp3")
        .on("end", () => resolve()) // Fun√ß√£o vazia que respeita o tipo `() => void`
        .on("error", reject)
        .save(outputPath);
    });

    // Transcreve o √°udio com Whisper
    console.log("Transcrevendo o √°udio...");
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(outputPath) as any,
      model: "whisper-1",
      language: "pt",
    });

    // Remove arquivos tempor√°rios
    fs.unlinkSync(inputPath);
    fs.unlinkSync(outputPath);

    console.log("Transcri√ß√£o conclu√≠da:", transcription.text);
    return transcription.text;
  } catch (error) {
    console.error("Erro ao processar o √°udio:", error);
    throw new Error("N√£o foi poss√≠vel processar o √°udio enviado.");
  }
};
